{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Task 1\n",
    "\n",
    "Build a classifier using the perceptron algorithm. Figure out if dataset is linearly seperable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from preprocessor import Preprocessor\n",
    "from Models.Perceptron import Perceptron\n",
    "import warnings \n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../dataset.csv\")\n",
    "dataset.drop(columns=[\"id\"],inplace=True)\n",
    "# Creating a dataframe to store the results\n",
    "results = pd.DataFrame(columns=[\"threshold\",\"delta\",\"method\",\"mean_accuracy\",\"std_accuracy\",\"epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 'B', 1: 'M'}\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(dataset,\"diagnosis\")\n",
    "splits = preprocessor.preprocess(drop_na=True,n_splits=10,standardize=False,labels=[-1,1]) # splitting into training and testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using training data as given"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using an infinite loop for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n"
     ]
    }
   ],
   "source": [
    "#PM1 is perceptron model 1 without shuffling training data\n",
    "pm1 = Perceptron()\n",
    "accuracies:list[float]=[]\n",
    "for split in splits:\n",
    "    train, test = split\n",
    "    X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "    X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "    pm1.fit(X_train,y_train,True)\n",
    "    tp,tn,fp,fn=pm1.score(X_test,y_test)\n",
    "    accuracies.append((tp + tn) / (tp + tn + fp + fn))\n",
    "result_dict ={\"threshold\":100,\"delta\":0.001,\"method\":\"PM1-Infinite\",\n",
    "              \"mean_accuracy\": np.round((np.mean(accuracies)*100), 2),\n",
    "        \"std_accuracy\": np.round((np.std(accuracies)*100), 2)\n",
    "              ,\"epochs\":None}\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using epochs instead of infinite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies:list[float]=[]\n",
    "for split in splits:\n",
    "    train, test = split\n",
    "    X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "    X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "    pm1.fit(X_train,y_train,False,epochs=1000)\n",
    "    tp,tn,fp,fn=pm1.score(X_test,y_test)\n",
    "    accuracies.append((tp + tn) / (tp + tn + fp + fn))\n",
    "result_dict ={\"threshold\":None,\"delta\":None,\"method\":\"PM1-Epochs\",\n",
    "              \"mean_accuracy\": np.round((np.mean(accuracies)*100), 2),\n",
    "                \"std_accuracy\": np.round((np.std(accuracies)*100), 2)\n",
    "              ,\"epochs\":1000}\n",
    "results = results.append(result_dict,ignore_index=True)\n",
    "## As epochs increases we break if if we get 100 percent accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2 = Perceptron()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an infinite loop with some threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n"
     ]
    }
   ],
   "source": [
    "accuracies:list[float]=[]\n",
    "for split in splits:\n",
    "    train, test = split\n",
    "    train = train.sample(frac=1).reset_index(drop=True)\n",
    "    X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "    X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "    pm2.fit(X_train,y_train,True)\n",
    "    tp,tn,fp,fn=pm2.score(X_test,y_test)\n",
    "    accuracies.append((tp + tn) / (tp + tn + fp + fn))\n",
    "result_dict ={\"threshold\":100,\"delta\":0.001,\"method\":\"PM2-Infinite\",\n",
    "              \"mean_accuracy\": np.round((np.mean(accuracies)*100), 2),\n",
    "                \"std_accuracy\": np.round((np.std(accuracies)*100), 2)\n",
    "              ,\"epochs\":None\n",
    "              }\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies:list[float]=[]\n",
    "for split in splits:\n",
    "    train, test = split\n",
    "    train = train.sample(frac=1).reset_index(drop=True)\n",
    "    X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "    X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "    pm2.fit(X_train,y_train,False,epochs=1000)\n",
    "    tp,tn,fp,fn=pm2.score(X_test,y_test)\n",
    "    accuracies.append((tp + tn) / (tp + tn + fp + fn))\n",
    "result_dict ={\"threshold\":None,\"delta\":None,\"method\":\"PM2-Epochs\",\n",
    "              \"mean_accuracy\": np.round((np.mean(accuracies)*100), 2),\n",
    "                \"std_accuracy\": np.round((np.std(accuracies)*100), 2)\n",
    "              ,\"epochs\":1000}\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Task 2\n",
    "\n",
    "Build a perceptron model on normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 'B', 1: 'M'}\n"
     ]
    }
   ],
   "source": [
    "splits = preprocessor.preprocess(n_splits=10,standardize=True,labels=[-1,1]) # splitting into training and testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an infinite loop that terminates on some learning threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking as learnt perfect decision boundary\n",
      "Breaking as learnt perfect decision boundary\n",
      "Breaking as learnt perfect decision boundary\n",
      "Breaking as learnt perfect decision boundary\n",
      "Breaking as learnt perfect decision boundary\n",
      "Breaking as learnt perfect decision boundary\n",
      "Breaking as learnt perfect decision boundary\n",
      "Breaking as learnt perfect decision boundary\n",
      "Breaking as learnt perfect decision boundary\n",
      "Breaking as learnt perfect decision boundary\n"
     ]
    }
   ],
   "source": [
    "pm3 = Perceptron()\n",
    "accuracies:list[float]=[]\n",
    "for split in splits:\n",
    "    train, test = split\n",
    "    X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "    X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "    pm3.fit(X_train,y_train,True)\n",
    "    tp,tn,fp,fn=pm3.score(X_test,y_test)\n",
    "    accuracies.append((tp + tn) / (tp + tn + fp + fn))\n",
    "result_dict ={\"threshold\":100,\"delta\":0.001,\"method\":\"PM3-Infinite\",\n",
    "              \"mean_accuracy\": np.round((np.mean(accuracies)*100), 2),\n",
    "                \"std_accuracy\": np.round((np.std(accuracies)*100), 2)\n",
    "              ,\"epochs\":None\n",
    "              }\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies:list[float]=[]\n",
    "for split in splits:\n",
    "    train, test = split\n",
    "    X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "    X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "    pm3.fit(X_train,y_train,inf_loop=False,epochs=1000)\n",
    "    tp,tn,fp,fn=pm3.score(X_test,y_test)\n",
    "    accuracies.append((tp + tn) / (tp + tn + fp + fn))\n",
    "result_dict ={\"threshold\":None,\"delta\":None,\"method\":\"PM3-Epochs\",\n",
    "              \"mean_accuracy\": np.round((np.mean(accuracies)*100), 2),\n",
    "                \"std_accuracy\": np.round((np.std(accuracies)*100), 2)\n",
    "              ,\"epochs\":1000}\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Task 3\n",
    "\n",
    "Change the order of the features in the dataset randomly and build a perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 'B', 1: 'M'}\n"
     ]
    }
   ],
   "source": [
    "splits = preprocessor.preprocess(drop_na=True,n_splits=10,standardize=False,labels=[-1,1]) # splitting into training and testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an infinite loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n",
      "Breaking as not improving\n"
     ]
    }
   ],
   "source": [
    "pm4 = Perceptron()\n",
    "accuracies:list[float]=[]\n",
    "for split in splits:\n",
    "    train, test = split\n",
    "    train = train.sample(frac=1,axis = 1,random_state=23)\n",
    "    test = test.sample(frac=1,axis = 1,random_state=23)\n",
    "    X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "    X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "    pm4.fit(X_train,y_train,True)\n",
    "    tp,tn,fp,fn=pm4.score(X_test,y_test)\n",
    "    accuracies.append((tp + tn) / (tp + tn + fp + fn))\n",
    "result_dict ={\"threshold\":100,\"delta\":0.001,\"method\":\"PM4-Infinite\",\n",
    "              \"mean_accuracy\": np.round((np.mean(accuracies)*100), 2),\n",
    "                \"std_accuracy\": np.round((np.std(accuracies)*100), 2)\n",
    "              ,\"epochs\":None\n",
    "              }\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies:list[float]=[]\n",
    "for split in splits:\n",
    "    train, test = split\n",
    "    train = train.sample(frac=1,axis = 1,random_state=23)\n",
    "    test = test.sample(frac=1,axis = 1,random_state=23)\n",
    "    X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "    X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "    pm4.fit(X_train,y_train,inf_loop=False,epochs=1000)\n",
    "    tp,tn,fp,fn=pm4.score(X_test,y_test)\n",
    "    accuracies.append((tp + tn) / (tp + tn + fp + fn))\n",
    "result_dict ={\"threshold\":None,\"delta\":None,\"method\":\"PM4-Epochs\",\n",
    "              \"mean_accuracy\": np.round((np.mean(accuracies)*100), 2),\n",
    "                \"std_accuracy\": np.round((np.std(accuracies)*100), 2)\n",
    "              ,\"epochs\":1000}\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>delta</th>\n",
       "      <th>method</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>PM3-Infinite</td>\n",
       "      <td>94.24</td>\n",
       "      <td>0.94</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PM3-Epochs</td>\n",
       "      <td>94.24</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PM1-Epochs</td>\n",
       "      <td>91.41</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PM4-Epochs</td>\n",
       "      <td>91.41</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>PM1-Infinite</td>\n",
       "      <td>91.11</td>\n",
       "      <td>2.11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>PM4-Infinite</td>\n",
       "      <td>91.11</td>\n",
       "      <td>2.11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PM2-Epochs</td>\n",
       "      <td>89.04</td>\n",
       "      <td>5.59</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>PM2-Infinite</td>\n",
       "      <td>86.62</td>\n",
       "      <td>5.67</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  threshold  delta        method  mean_accuracy  std_accuracy epochs\n",
       "4       100  0.001  PM3-Infinite          94.24          0.94   None\n",
       "5      None    NaN    PM3-Epochs          94.24          0.94   1000\n",
       "1      None    NaN    PM1-Epochs          91.41          2.26   1000\n",
       "7      None    NaN    PM4-Epochs          91.41          2.26   1000\n",
       "0       100  0.001  PM1-Infinite          91.11          2.11   None\n",
       "6       100  0.001  PM4-Infinite          91.11          2.11   None\n",
       "3      None    NaN    PM2-Epochs          89.04          5.59   1000\n",
       "2       100  0.001  PM2-Infinite          86.62          5.67   None"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=[\"mean_accuracy\"],ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Task 1\n",
    "\n",
    "Since perceptron is an algorithm which varies depending on the order of the training data, we observe that the PM1 accuracies and PM2 accuracies vary buy around 2 percent. This is because the training samples were shuffled in PM2 which gave a different model that classified the testing data differently\n",
    "\n",
    "#### Learning Task 2\n",
    "\n",
    "In this model we normalize the data twice, once with respect to the training sample's mean and the testing sample's mean(the code which is available in the preprocessor file). Since normalized data treats all the features with equal weightage, we observe that it gives a higher accuracy with respect to PM1. \n",
    "\n",
    "#### Learning Task 3\n",
    "\n",
    "The order of the tuples in Perceptron does not matter as in the end we get the same weights but in a shuffled order, which denotes the same decision boundary. Hence we get the same accuracy for both pm1 and pm4. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
