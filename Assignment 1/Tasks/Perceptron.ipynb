{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Task 1\n",
    "\n",
    "Build a classifier using the perceptron algorithm. Figure out if dataset is linearly seperable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from preprocessor import Preprocessor\n",
    "from Models.Perceptron import Perceptron\n",
    "import warnings \n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../dataset.csv\")\n",
    "dataset.drop(columns=[\"id\"],inplace=True)\n",
    "# Creating a dataframe to store the results\n",
    "results = pd.DataFrame(columns=[\"threshold\",\"delta\",\"method\",\"accuracy\",\"epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(dataset,\"diagnosis\")\n",
    "splits = preprocessor.preprocess(drop_na=True,n_splits=10,standardize=False,labels=[-1,1]) # splitting into training and testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using training data as given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PM1 is perceptron model 1 without shuffling training data\n",
    "pm1 = Perceptron()\n",
    "train, test = splits[0]\n",
    "X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using an infinite loop for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking as not improving\n"
     ]
    }
   ],
   "source": [
    "pm1.fit(X_train,y_train,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Results--------\n",
      "Accuracy: 0.8986301369863013\n",
      "----Class 1----\n",
      "Precision: 0.7686567164179104\n",
      "Recall: 0.944954128440367\n",
      "----Class 0----\n",
      "Precision: 0.974025974025974\n",
      "Recall: 0.87890625\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn=pm1.score(X_train,y_train,_print = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Results--------\n",
      "Accuracy: 0.9343434343434344\n",
      "----Class 1----\n",
      "Precision: 0.9587628865979382\n",
      "Recall: 0.9117647058823529\n",
      "----Class 0----\n",
      "Precision: 0.9108910891089109\n",
      "Recall: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn=pm1.score(X_test,y_test,_print=True)\n",
    "result_dict ={\"threshold\":100,\"delta\":0.001,\"method\":\"PM1-Infinite loop\",\n",
    "              \"accuracy\":(tp+tn)/(tp+tn+fp+fn)\n",
    "              ,\"epochs\":None}\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using epochs instead of infinite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm1.fit(X_train,y_train,False,epochs=10000)\n",
    "## As epochs increases we break if if we get 100 percent accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Results--------\n",
      "Accuracy: 0.8383838383838383\n",
      "----Class 1----\n",
      "Precision: 1.0\n",
      "Recall: 0.6862745098039216\n",
      "----Class 0----\n",
      "Precision: 0.75\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn=pm1.score(X_test,y_test,_print=True)\n",
    "acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "result_dict ={\"threshold\":None,\"delta\":None,\"method\":\"PM1-Epochs\",\n",
    "              \"accuracy\":(tp+tn)/(tp+tn+fp+fn)\n",
    "              ,\"epochs\":1000}\n",
    "results = results.append(result_dict,ignore_index=True)\n",
    "### Shuffling the training data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2 = Perceptron()\n",
    "X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "#### Using an infinite loop with some threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using an infinite loop with some threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking as learnt perfect decision boundary\n"
     ]
    }
   ],
   "source": [
    "pm2.fit(X_train,y_train,inf_loop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Results--------\n",
      "Accuracy: 0.8383838383838383\n",
      "----Class 1----\n",
      "Precision: 1.0\n",
      "Recall: 0.6862745098039216\n",
      "----Class 0----\n",
      "Precision: 0.75\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn=pm2.score(X_test,y_test,_print=True)\n",
    "result_dict ={\"threshold\":100,\"delta\":0.001,\"method\":\"PM2-InfiniteLoop\",\n",
    "              \"accuracy\":(tp+tn)/(tp+tn+fp+fn)\n",
    "              ,\"epochs\":None\n",
    "              }\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2.fit(X_train,y_train,inf_loop=False,epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Results--------\n",
      "Accuracy: 0.8383838383838383\n",
      "----Class 1----\n",
      "Precision: 1.0\n",
      "Recall: 0.6862745098039216\n",
      "----Class 0----\n",
      "Precision: 0.75\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn=pm2.score(X_test,y_test,_print=True)\n",
    "result_dict ={\"threshold\":None,\"delta\":None,\"method\":\"PM2-Epochs\",\n",
    "              \"accuracy\":(tp+tn)/(tp+tn+fp+fn)\n",
    "              ,\"epochs\":1000}\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Task 2\n",
    "\n",
    "Build a perceptron model on normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = preprocessor.preprocess(n_splits=1,standardize=True,labels=[-1,1]) # splitting into training and testing\n",
    "train, test = splits[0]\n",
    "X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an infinite loop that terminates on some learning threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking as learnt perfect decision boundary\n"
     ]
    }
   ],
   "source": [
    "pm3 = Perceptron()\n",
    "pm3.fit(X_train,y_train,inf_loop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Results--------\n",
      "Accuracy: 0.9545454545454546\n",
      "----Class 1----\n",
      "Precision: 0.9696969696969697\n",
      "Recall: 0.9411764705882353\n",
      "----Class 0----\n",
      "Precision: 0.9393939393939394\n",
      "Recall: 0.96875\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn = pm3.score(X_test,y_test,_print=True)\n",
    "result_dict ={\"threshold\":100,\"delta\":0.001,\"method\":\"PM3-Infinite\",\n",
    "              \"accuracy\":(tp+tn)/(tp+tn+fp+fn)\n",
    "              ,\"epochs\":None\n",
    "              }\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = preprocessor.preprocess(drop_na=True,n_splits=1,standardize=True,labels=[-1,1]) # splitting into training and testing\n",
    "train, test = splits[0]\n",
    "X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "pm3.fit(X_train,y_train,inf_loop=False,epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Results--------\n",
      "Accuracy: 0.9545454545454546\n",
      "----Class 1----\n",
      "Precision: 0.9696969696969697\n",
      "Recall: 0.9411764705882353\n",
      "----Class 0----\n",
      "Precision: 0.9393939393939394\n",
      "Recall: 0.96875\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn=pm3.score(X_test,y_test,_print=True)\n",
    "result_dict ={\"threshold\":None,\"delta\":None,\"method\":\"PM3-Epochs\",\n",
    "              \"accuracy\":(tp+tn)/(tp+tn+fp+fn)\n",
    "              ,\"epochs\":1000}\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Task 3\n",
    "\n",
    "Change the order of the features in the dataset randomly and build a perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = preprocessor.preprocess(drop_na=True,n_splits=10,standardize=False,labels=[-1,1]) # splitting into training and testing\n",
    "train, test = splits[0]\n",
    "seed = random.randint(0,100)\n",
    "train = train.sample(frac=1,axis = 1,random_state=23)\n",
    "test = test.sample(frac=1,axis = 1,random_state=23)\n",
    "X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an infinite loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking as not improving\n"
     ]
    }
   ],
   "source": [
    "pm4 = Perceptron()\n",
    "pm4.fit(X_train,y_train,inf_loop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Results--------\n",
      "Accuracy: 0.9343434343434344\n",
      "----Class 1----\n",
      "Precision: 0.9587628865979382\n",
      "Recall: 0.9117647058823529\n",
      "----Class 0----\n",
      "Precision: 0.9108910891089109\n",
      "Recall: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn = pm4.score(X_test,y_test,_print = True)\n",
    "result_dict ={\"threshold\":100,\"delta\":0.001,\"method\":\"PM4-Infinite\",\n",
    "              \"accuracy\":(tp+tn)/(tp+tn+fp+fn)\n",
    "              ,\"epochs\":None\n",
    "              }\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = random.randint(0,100)\n",
    "preprocessor.data.sample(frac=1,axis=1,random_state=seed)\n",
    "splits = preprocessor.preprocess(drop_na=True,n_splits=10,standardize=False,labels=[-1,1]) # splitting into training and testing\n",
    "train, test = splits[0]\n",
    "\n",
    "# train = train.sample(frac=1,axis = 1,random_state=23)\n",
    "# test = test.sample(frac=1,axis = 1,random_state=23)\n",
    "X_train, y_train = train.drop(columns=[\"diagnosis\"]).to_numpy(), train[\"diagnosis\"].to_numpy()\n",
    "X_test, y_test = test.drop(columns=[\"diagnosis\"]).to_numpy(), test[\"diagnosis\"].to_numpy()\n",
    "\n",
    "pm4.fit(X_train,y_train,inf_loop=False,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Results--------\n",
      "Accuracy: 0.9191919191919192\n",
      "----Class 1----\n",
      "Precision: 0.8981481481481481\n",
      "Recall: 0.9509803921568627\n",
      "----Class 0----\n",
      "Precision: 0.9444444444444444\n",
      "Recall: 0.8854166666666666\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn=pm4.score(X_test,y_test,_print=True)\n",
    "result_dict ={\"threshold\":None,\"delta\":None,\"method\":\"PM4-Epochs\",\n",
    "              \"accuracy\":(tp+tn)/(tp+tn+fp+fn)\n",
    "              ,\"epochs\":1000}\n",
    "results = results.append(result_dict,ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>delta</th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Infinite loop without shuffling</td>\n",
       "      <td>0.934343</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Using epochs without shuffling training data(N...</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Infinite loop (On shuffled training data)</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Epochs (shuffled training data)</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Infinite loop (On normalized data)</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Epochs (normalized data)</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Infinite loop (On shuffled attributes)</td>\n",
       "      <td>0.934343</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Epochs (shuffled attributes)</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  threshold  delta                                             method  \\\n",
       "0       100  0.001                    Infinite loop without shuffling   \n",
       "1      None    NaN  Using epochs without shuffling training data(N...   \n",
       "2       100  0.001          Infinite loop (On shuffled training data)   \n",
       "3      None    NaN                    Epochs (shuffled training data)   \n",
       "4       100  0.001                 Infinite loop (On normalized data)   \n",
       "5      None    NaN                           Epochs (normalized data)   \n",
       "6       100  0.001             Infinite loop (On shuffled attributes)   \n",
       "7      None    NaN                       Epochs (shuffled attributes)   \n",
       "\n",
       "   accuracy epochs  \n",
       "0  0.934343   None  \n",
       "1  0.838384   1000  \n",
       "2  0.838384   None  \n",
       "3  0.838384   1000  \n",
       "4  0.954545   None  \n",
       "5  0.954545   1000  \n",
       "6  0.934343   None  \n",
       "7  0.919192   1000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
